{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FID.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumarmanishjha/pgm-prjoject_A18/blob/master/FID.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "0zyp9s7G6nay",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Imj2IqYuXFcf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "605b2182-d312-4b46-956e-9fcbbe6314b3"
      },
      "cell_type": "code",
      "source": [
        "# clone FID repo if you don't have done it already !\n",
        "!git clone https://github.com/mseitzer/pytorch-fid.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorch-fid'...\n",
            "remote: Enumerating objects: 17, done.\u001b[K\n",
            "remote: Total 17 (delta 0), reused 0 (delta 0), pack-reused 17\u001b[K\n",
            "Unpacking objects: 100% (17/17), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2K1R7o2u6uC8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3454c573-c159-4112-82b1-587f9ce2d180"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import time\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "folder_path = 'drive/My Drive/results/MNIST_GAN_results/'\n",
        "  \n",
        "path_real_data = folder_path + 'real_samples/'\n",
        "path_generated_data = folder_path + 'gen_samples/'\n",
        "\n",
        "if not os.path.exists(path_real_data):\n",
        "    raise RuntimeError('Invalid path real samples: %s' % path_real_data)\n",
        "if not os.path.exists(path_generated_data):\n",
        "    raise RuntimeError('Invalid path generated samples: %s' % path_generated_data)\n",
        "    \n",
        "# CPU or GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    use_cuda = True\n",
        "    print('using cuda !')\n",
        "else:\n",
        "    raise RuntimeError('GPU not avaialble !')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "using cuda !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jw768Rog8IGZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "5d05a0db-ca26-4a4a-8dbe-62510c5c9587"
      },
      "cell_type": "code",
      "source": [
        "print(os.getcwd())\n",
        "#os.chdir('..') \n",
        "#print(os.getcwd())\n",
        "print(os.listdir())\n",
        "\n",
        "# start the computation of FID\n",
        "!python pytorch-fid/fid_score.py 'drive/My Drive/results/MNIST_GAN_results/real_samples/' 'drive/My Drive/results/MNIST_GAN_results/gen_samples/' --gpu 0\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "['.config', 'pytorch-fid', 'drive', 'sample_data']\n",
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\" to /root/.torch/models/inception_v3_google-1a9a5a14.pth\n",
            "100% 108857766/108857766 [00:02<00:00, 42258277.85it/s]\n",
            "pytorch-fid/fid_score.py:103: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  batch = Variable(batch, volatile=True)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1961: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "FID:  50.25906175000503\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}