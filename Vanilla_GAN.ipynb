{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vanilla_GAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumarmanishjha/pgm-prjoject_A18/blob/master/Vanilla_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "J0hITJKAgb5f",
        "colab_type": "code",
        "outputId": "8c307458-15ec-4019-8fee-5dce9d3ebe1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "  \n",
        "!pip install imageio  "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x57bda000 @  0x7f0f4edd12a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
            "Collecting imageio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/b4/cbb592964dfd71a9de6a5b08f882fd334fb99ae09ddc82081dbb2f718c81/imageio-2.4.1.tar.gz (3.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 3.3MB 9.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageio) (1.14.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio) (5.3.0)\n",
            "Building wheels for collected packages: imageio\n",
            "  Running setup.py bdist_wheel for imageio ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/e0/43/31/605de9372ceaf657f152d3d5e82f42cf265d81db8bbe63cde1\n",
            "Successfully built imageio\n",
            "Installing collected packages: imageio\n",
            "Successfully installed imageio-2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7pmQU4sLK0Gw",
        "colab_type": "code",
        "outputId": "0908dce0-ef69-4682-c3be-dc406e8de14f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "added_path = 'drive/My Drive/results/MNIST_GAN_results/'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yLhGMMF0gWAT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "p8Ty_Kb8gVSF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import imageio\n",
        "from torch.autograd import Variable\n",
        "import itertools\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YoCgCVQKgJfo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Data set"
      ]
    },
    {
      "metadata": {
        "id": "mClClq_SgI9H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# dataset\n",
        "\n",
        "train_MNIST = True\n",
        "train_CIFAR_10 = False\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "if train_MNIST:\n",
        "  train_data = datasets.MNIST('../data', train=True, \n",
        "                            download=True, transform=transform)\n",
        "  \n",
        "  image_size = 28\n",
        "  n_channels = 1 \n",
        "  # test_data = datasets.MNIST('../data', train=False, transform=transform)\n",
        "  \n",
        "elif train_CIFAR_10:\n",
        "  # CIFAR 10 Data set !!\n",
        "  train_data = datasets.CIFAR10(root='./data', train=True,\n",
        "                              download=True, transform=transform)\n",
        "  \n",
        "  image_size = 32\n",
        "  n_channels = 3 \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LDOimlIHlVVi",
        "colab_type": "code",
        "outputId": "dc393485-beec-4523-d36a-ecb2dc88b5e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        }
      },
      "cell_type": "code",
      "source": [
        "# This parameter influences optimization\n",
        "batch_size = 128\n",
        "# This is just for evaluation, we want is as big as the GPU can support\n",
        "batch_size_eval = 512\n",
        "\n",
        "# CPU or GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    use_cuda = True\n",
        "    print('using cuda !')\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    use_cuda = False\n",
        "    \n",
        "indices = list(range(len(train_data)))\n",
        "random.shuffle(indices)\n",
        "\n",
        "n_data_total = len(train_data)\n",
        "n_valid = 0\n",
        "n_train_images = n_data_total - n_valid\n",
        "print('n_data_total =', n_data_total, '; n_train_images =', \n",
        "       n_train_images, '; n_valid =', n_valid)\n",
        "\n",
        "\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = DataLoader(\n",
        "    train_data,\n",
        "    batch_size=batch_size,\n",
        "    sampler=SubsetRandomSampler(indices[n_valid:]),\n",
        "    #num_workers=1,\n",
        "    pin_memory=use_cuda\n",
        ")\n",
        "\n",
        "#valid_loader = DataLoader(\n",
        "#    train_data,\n",
        "#    batch_size=batch_size_eval,\n",
        "#    sampler=SubsetRandomSampler(indices[:n_valid]),\n",
        "#    #num_workers=1,\n",
        "#    pin_memory=use_cuda,\n",
        "#)\n",
        "\n",
        "\n",
        "# visualize and understand the data\n",
        "for inputs, targets in train_loader:\n",
        "    print(\"This is the shape of one batch:\", inputs.shape)\n",
        "    img = inputs[0, 0]\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    plt.imshow(img, cmap='Greys_r')\n",
        "    break    "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using cuda !\n",
            "n_data_total = 60000 ; n_train_images = 60000 ; n_valid = 0\n",
            "This is the shape of one batch: torch.Size([128, 1, 28, 28])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYQkABv8P+xN9ObpbcpEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fa59d55eda0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "XlFpenmYl46M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Samplers"
      ]
    },
    {
      "metadata": {
        "id": "dT_u5EKFl4MM",
        "colab_type": "code",
        "outputId": "9ec35eeb-6a2c-4385-b238-3b55d7ac0f44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "def gaussian_noise_sampler(mu, sigma, device):\n",
        "    \"\"\" Gaussian input to the generator\"\"\"\n",
        "    return lambda m, n: torch.Tensor(np.random.normal(mu, sigma, (m, n))).to(device)\n",
        "\n",
        "\n",
        "def uniform_noise_sampler(a, b, device):\n",
        "    \"\"\" Uniform input to the generator of a m x n tensor\"\"\"\n",
        "    return lambda m, n: (b - a) * torch.rand(m, n).to(device) + a\n",
        "  \n",
        "def plot_a_gen_sample(gen_sample):\n",
        "    img = gen_sample.view(image_size, image_size)\n",
        "    plt.imshow(img, cmap='Greys_r')  \n",
        "    plt.show()\n",
        "\n",
        "# We feed in the generator a noise input   \n",
        "# Uniform sampler on [-1, 1]\n",
        "g_noise_input_generator = uniform_noise_sampler(-1, 1, device)\n",
        "# Input noise of size 100\n",
        "dim_gen_input = 100 \n",
        "\n",
        "fixed_noise = g_noise_input_generator(5 * 5, dim_gen_input)\n",
        "\n",
        "def show_result(model_G, dim_gen_input, num_epoch,\n",
        "                show = False, save = False, path = 'result.png', isFix=False):\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      \n",
        "      random_noise = g_noise_input_generator(5 * 5, dim_gen_input)\n",
        "\n",
        "      if isFix:\n",
        "          test_images = model_G(fixed_noise)\n",
        "      else:\n",
        "          test_images = model_G(random_noise)\n",
        "\n",
        "      size_figure_grid = 5\n",
        "      fig, ax = plt.subplots(size_figure_grid, size_figure_grid, figsize=(5, 5))\n",
        "      for i, j in itertools.product(range(size_figure_grid), range(size_figure_grid)):\n",
        "          ax[i, j].get_xaxis().set_visible(False)\n",
        "          ax[i, j].get_yaxis().set_visible(False)\n",
        "\n",
        "      for k in range(5*5):\n",
        "          i = k // 5\n",
        "          j = k % 5\n",
        "          ax[i, j].cla()\n",
        "          ax[i, j].imshow(test_images[k, :].cpu().data.view(image_size, image_size).numpy(), cmap='gray')\n",
        "\n",
        "      label = 'Epoch {0}'.format(num_epoch)\n",
        "      fig.text(0.5, 0.04, label, ha='center')\n",
        "      plt.savefig(path)\n",
        "\n",
        "      if show:\n",
        "          plt.show()\n",
        "      else:\n",
        "          plt.close()\n",
        "        \n",
        "    \n",
        "def show_train_hist(hist, show = False, save = False, path = 'Train_hist.png'):\n",
        "    x = range(len(hist['D_losses']))\n",
        "\n",
        "    y1 = hist['D_losses']\n",
        "    y2 = hist['G_losses']\n",
        "\n",
        "    plt.plot(x, y1, label='D_loss')\n",
        "    plt.plot(x, y2, label='G_loss')\n",
        "\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "\n",
        "    plt.legend(loc=4)\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save:\n",
        "        plt.savefig(path)\n",
        "\n",
        "    if show:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.close()   \n",
        "  \n",
        "print('ok')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ok\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XL0d-12qftha",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Standard slope of the leak of LeakyReLU is 0.01, 0.2 recommended by DCGAN paper\n",
        "# but 0.2 seems to work very badly on our 2d data sets\n",
        "slope_leaky_relu = 0.2\n",
        "# 'k' steps in the original GAN paper. Can put the discriminator on higher training freq than generator\n",
        "d_steps = 1\n",
        "g_steps = 1\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  \n",
        "    def __init__(self, dim_input, dim_output):\n",
        "        super(Generator, self).__init__()\n",
        "        # fc for fully connected layer\n",
        "        self.fc1 = nn.Linear(dim_input, 256)\n",
        "        self.fc2 = nn.Linear(256, 512)\n",
        "        self.fc3 = nn.Linear(512, 1024)\n",
        "        self.fc4 = nn.Linear(1024, dim_output)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # From https://github.com/soumith/ganhacks,\n",
        "        # use LeakyReLU to avoid sparse gradients\n",
        "        x = x.view(x.size(0), -1) # flatten\n",
        "        x = F.leaky_relu(self.fc1(x), negative_slope=slope_leaky_relu)\n",
        "        x = F.leaky_relu(self.fc2(x), negative_slope=slope_leaky_relu)\n",
        "        x = F.leaky_relu(self.fc3(x), negative_slope=slope_leaky_relu)\n",
        "        x = self.tanh(self.fc4(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "dim_images = int(image_size ** 2)\n",
        "\n",
        "model_G = Generator(dim_gen_input, dim_images).to(device)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, dim_input, output_size):\n",
        "        super(Discriminator, self).__init__()\n",
        "        # fc for fully connected layer\n",
        "        self.fc1 = nn.Linear(dim_input, 1024)\n",
        "        self.dropout_1 = nn.Dropout(0.3)\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.dropout_2 = nn.Dropout(0.3)\n",
        "        self.fc3 = nn.Linear(512, 256)\n",
        "        self.dropout_3 = nn.Dropout(0.3)\n",
        "        self.fc4 = nn.Linear(256, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # From https://github.com/soumith/ganhacks,\n",
        "        # use LeakyReLU to avoid sparse gradients\n",
        "        x = x.view(x.size(0), -1) # flatten\n",
        "        x = F.leaky_relu(self.fc1(x), negative_slope=slope_leaky_relu)\n",
        "        x = self.dropout_1(x)\n",
        "        x = F.leaky_relu(self.fc2(x), negative_slope=slope_leaky_relu)\n",
        "        x = self.dropout_2(x)\n",
        "        x = F.leaky_relu(self.fc3(x), negative_slope=slope_leaky_relu)\n",
        "        x = self.dropout_3(x)\n",
        "        # Training a standard binary classifier with a\n",
        "        # sigmoid output (--> using Binary Cross Entropy Loss)\n",
        "        return torch.sigmoid(self.fc4(x))\n",
        "\n",
        "\n",
        "# Single dimension for 'real' vs. 'fake'\n",
        "# We can change this if we want to use gans that also classify\n",
        "d_output_size = 1\n",
        "\n",
        "model_D = Discriminator(dim_images, d_output_size).to(device)\n",
        "\n",
        "\n",
        "# Use same learning rates  for generator + discriminator\n",
        "# Learning rates recommended by the DCGAN paper for Adam\n",
        "learning_rate = 2e-4\n",
        "# From https://github.com/soumith/ganhacks, use Adam Optimizer\n",
        "d_optimizer = optim.Adam(model_D.parameters(), lr=learning_rate)\n",
        "g_optimizer = optim.Adam(model_G.parameters(), lr=learning_rate)\n",
        "# use binary cross entropy loss function\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "arr_gradient_D = []\n",
        "arr_gradient_G = []\n",
        "arr_means = []\n",
        "arr_std_dev = []\n",
        "# set to true or false to plot the mean and std_dev\n",
        "plot_means_and_var = False\n",
        "\n",
        "real_label = 1\n",
        "fake_label = 0\n",
        "\n",
        "# results save folder\n",
        "if not os.path.isdir(added_path):\n",
        "    os.mkdir(added_path)\n",
        "if not os.path.isdir(added_path + 'Random_results'):\n",
        "    os.mkdir(added_path + 'Random_results')\n",
        "if not os.path.isdir(added_path + 'Fixed_results'):\n",
        "    os.mkdir(added_path + 'Fixed_results')\n",
        "\n",
        "train_hist = {}\n",
        "train_hist['D_losses'] = []\n",
        "train_hist['G_losses'] = []\n",
        "\n",
        "\n",
        "def train(model_G, model_D, epoch):\n",
        "\n",
        "    model_D.train()\n",
        "    model_G.train()\n",
        "    \n",
        "    D_losses = []\n",
        "    G_losses = []\n",
        "    \n",
        "    time_now = time.clock()\n",
        "\n",
        "    for batch_idx, (inputs, target) in enumerate(train_loader):\n",
        "        inputs, target = inputs.to(device), target.to(device)\n",
        "          \n",
        "        for d_index in range(d_steps):\n",
        "\n",
        "            # (1) Update Discriminator : maximize log(D(x)) + log(1 - D(G(z)))\n",
        "            \n",
        "            # this is not necessarily equal to batch size !\n",
        "            n_images = len(inputs)\n",
        "            \n",
        "            # Reset gradients\n",
        "            model_D.zero_grad()\n",
        "\n",
        "            # on real samples\n",
        "            d_real_decision = model_D(inputs)\n",
        "\n",
        "            # To compute BCE loss\n",
        "            label = torch.full((n_images, 1), real_label, device=device)\n",
        "            # D(x) should be 1 for real samples\n",
        "            d_real_loss = loss_fn(d_real_decision, label)\n",
        "\n",
        "            # on fake samples\n",
        "            d_gen_input = g_noise_input_generator(n_images, dim_gen_input)\n",
        "            d_fake_data = model_G(d_gen_input).detach()  # detach to avoid training G on these labels\n",
        "            d_fake_decision = model_D(d_fake_data)\n",
        "            # D(x) now wants to be as close as possible as fake label value\n",
        "            f_label = torch.full((n_images, 1), fake_label, device=device)\n",
        "            d_fake_loss = loss_fn(d_fake_decision, f_label)\n",
        "            \n",
        "            # Total loss\n",
        "            d_train_loss = d_fake_loss + d_real_loss\n",
        "            d_train_loss.backward()\n",
        "            d_optimizer.step()  # Only optimizes D's parameters; changes based on stored gradients from backward()\n",
        "            \n",
        "            D_losses.append(d_train_loss.item())\n",
        "\n",
        "            # Compute the norm of gradient\n",
        "            total_norm = 0\n",
        "            for p in model_D.parameters():\n",
        "                norm = p.grad.data.norm(2)\n",
        "                total_norm += norm.item() ** 2\n",
        "            total_norm = np.sqrt(total_norm)\n",
        "            arr_gradient_D.append(total_norm)\n",
        "\n",
        "        for g_index in range(g_steps):\n",
        "\n",
        "            # (2) Update G network: maximize log(D(G(z)))\n",
        "            model_G.zero_grad()\n",
        "\n",
        "            gen_input = g_noise_input_generator(n_images, dim_gen_input)\n",
        "            gen_output = model_G(gen_input)\n",
        "            d_fake_decision = model_D(gen_output)\n",
        "\n",
        "            # The generator tries to get D(G(z)) near 1\n",
        "            label = torch.full((n_images, 1), real_label, device=device)\n",
        "            g_loss = loss_fn(d_fake_decision,  label)\n",
        "\n",
        "            g_loss.backward()\n",
        "            g_optimizer.step()\n",
        "            \n",
        "            G_losses.append(g_loss.item())\n",
        "\n",
        "            # Compute norm of gradient\n",
        "            total_norm = 0\n",
        "            for p in model_G.parameters():\n",
        "                norm = p.grad.data.norm(2)\n",
        "                total_norm += norm.item() ** 2\n",
        "            total_norm = np.sqrt(total_norm)\n",
        "            arr_gradient_G.append(total_norm)\n",
        "\n",
        "        if batch_idx % 50 == 0:            \n",
        "            # Store mean/std_dev            \n",
        "            if plot_means_and_var:\n",
        "                # Can't call numpy() on Variable that requires grad. Use var.detach().numpy() instead.\n",
        "                np_gen_output = gen_output.detach().numpy()\n",
        "                mean = np.mean(np_gen_output)\n",
        "                std_dev = np.std(np_gen_output)\n",
        "                arr_means.append(mean)\n",
        "                arr_std_dev.append(std_dev)\n",
        "                print('mean = ', mean, ' std_dev = ', std_dev)\n",
        "            \n",
        "            print('\\rTrain Epoch: {} [{}/{} ({:.0f}%)] Time per epoch: {:.2f}s\\t Gen_Loss: {:.4f}; D_Real_Loss: {:.4f}; D_Fake_Loss: {:.4f}'\n",
        "                  .format(epoch, batch_idx * len(inputs), n_train_images,\n",
        "                          100. * batch_idx / len(train_loader), n_train_images / (50 * batch_size) * (time.clock() - time_now), \n",
        "                          d_real_loss.item(), d_fake_loss.item(), g_loss.item()),\n",
        "                  end='')        \n",
        "            time_now = time.clock()\n",
        "                 \n",
        "    return D_losses, G_losses\n",
        "\n",
        "\n",
        "n_epochs = 100\n",
        "for ep in range(n_epochs):\n",
        "    D_losses, G_losses = train(model_G, model_D, ep)\n",
        "    \n",
        "    p = added_path + 'Random_results/MNIST_GAN_' + str(ep + 1) + '.png'\n",
        "    fixed_p = added_path + 'Fixed_results/MNIST_GAN_' + str(ep + 1) + '.png'\n",
        "    show_result(model_G, dim_gen_input, (ep + 1), save=True, path=p, isFix=False)\n",
        "    show_result(model_G, dim_gen_input, (ep + 1), save=True, path=fixed_p, isFix=True)\n",
        "    train_hist['D_losses'].append(torch.mean(torch.FloatTensor(D_losses)))\n",
        "    train_hist['G_losses'].append(torch.mean(torch.FloatTensor(G_losses)))\n",
        "\n",
        "    \n",
        "print(\"Training finish!... save training results\")\n",
        "torch.save(model_G.state_dict(), added_path + \"generator_param.pkl\")\n",
        "torch.save(model_D.state_dict(), added_path + \"discriminator_param.pkl\")\n",
        "with open(added_path + 'train_hist.pkl', 'wb') as f:\n",
        "    pickle.dump(train_hist, f)\n",
        "\n",
        "show_train_hist(train_hist, save=True, path= added_path + 'MNIST_GAN_train_hist.png')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E9CAyz0ssEdS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Generate some animation..? (haven't used it)\n",
        "images = []\n",
        "for ep in range(n_epochs):\n",
        "    img_name = added_path + 'Fixed_results/MNIST_GAN_' + str(ep + 1) + '.png'\n",
        "    images.append(imageio.imread(img_name))\n",
        "imageio.mimsave(added_path + 'generation_animation.gif', images, fps=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D8RusX1TSRVk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00dda1b2-5586-4c76-a66f-0ac07171e1a7"
      },
      "cell_type": "code",
      "source": [
        "# Save 10k MNIST images to a folder if you haven't already done so\n",
        "# This will allow FID comparing\n",
        "\n",
        "def save_real_images_data_set(path):\n",
        "  \n",
        "  test_data = datasets.MNIST('../data', train=False, transform=transform)\n",
        "\n",
        "  test_loader = DataLoader(\n",
        "    test_data,\n",
        "    batch_size=batch_size_eval,\n",
        "    #num_workers=1,\n",
        "    pin_memory=use_cuda,\n",
        "  )\n",
        "\n",
        "  time_now = time.clock() \n",
        "  n_test_data = len(test_data)\n",
        "\n",
        "  i = 0\n",
        "  for batch_idx, (inputs, target) in enumerate(test_loader):\n",
        "\n",
        "    n_inputs = len(inputs)\n",
        "\n",
        "    for j in range(n_inputs):\n",
        "        torchvision.utils.save_image(inputs[j, :].view(image_size, image_size), \n",
        "                                     path + 'img_' + str(i) + '.png', normalize = True)    \n",
        "        i += 1\n",
        "\n",
        "    print('\\r Real_Images_Saved [{}/{} ({:.0f}%)] Time estimated left: {:.2f}s'\n",
        "            .format(i, n_test_data, 100 * i / n_test_data, \n",
        "                    ((n_test_data - i) / batch_size) * (time.clock() - time_now)),   \n",
        "            end='')\n",
        "    time_now = time.clock()            \n",
        "   \n",
        "  \n",
        "path_real = added_path + 'real_samples/'    \n",
        "\n",
        "if not os.path.isdir(path_real):\n",
        "    os.mkdir(path_real)\n",
        "    save_real_images_data_set(path_real)\n",
        "else:\n",
        "    # don't compute twice !!\n",
        "    print('Real Samples folder is already there !')\n",
        " \n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Real Samples folder is already there !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4T3BvqyiPbDD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# need to install this to save images via pytorch.. \n",
        "!pip install Pillow==4.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sMS8ObX7-6Iu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1770b528-a1c4-4fea-f053-fefb9d5ef3ef"
      },
      "cell_type": "code",
      "source": [
        "# Generate 10k samples\n",
        "# by 100 batches of 100\n",
        "import torchvision.utils\n",
        "\n",
        "path_gen = added_path + 'gen_samples/'\n",
        "if not os.path.isdir(path_gen):\n",
        "    os.mkdir(path_gen)\n",
        "    \n",
        "\n",
        "time_now = time.clock() \n",
        "for i in range(100):\n",
        "  noise = g_noise_input_generator(100, dim_gen_input)\n",
        "  gen_images = model_G(noise)\n",
        "\n",
        "  for j in range(100):\n",
        "      torchvision.utils.save_image(gen_images[j, :].view(image_size, image_size), \n",
        "                        path_gen + 'img_' + str(i*100 + j) + '.png', normalize = True)    \n",
        "      \n",
        "  print('\\r Gen_Images_Saved [{}/{} ({:.0f}%)] Time estimated left: {:.2f}s'\n",
        "        .format((i + 1) * 100, 10000, (i + 1) / 100, (99 - i) * (time.clock() - time_now)),   \n",
        "         end='')\n",
        "  time_now = time.clock()\n",
        "          \n",
        "\n",
        "     \n",
        "  \n",
        "              \n",
        "    "
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Images_Saved [10000/100000 (0%)] Time estimated left: 0.00s"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}